{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPSI semaine 5 : Indépendances conditionnelles et réseaux bayésiens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice : Indépendances conditionnelles et réseaux bayésiens\n",
    "Dans ce TME, l'objectif est d'apprendre des réseaux bayésiens à partir de bases de données. Hormis la base asia, un exemple jouet relativement petit qui vous permettra de mettre au point les différents algorithmes du TME, et car, les autres bases correspondront à des distributions de probabilité de tailles raisonnables : \n",
    "\n",
    "|  nom de la base  |            provenance           | nombre d'evenements elementaires |\n",
    "|:----------------:|:-------------------------------:|:--------------------------------:|\n",
    "|       asia       |          BN repository          |                $256     $          |\n",
    "|       alarm      |          BN repository          |              $10^{16}   $               |\n",
    "|       adult      | UCI machine learning repository |              $10^{12}   $          |\n",
    "|        car       | UCI machine learning repository |               $6912     $          |\n",
    "| agaricus-lepiota | UCI machine learning repository |              $10^{16}   $        |\n",
    "\n",
    "\n",
    "Apprendre un réseau bayésien consiste à apprendre sa structure graphique ainsi que les paramètres de ses distributions de probabilité conditionnelles. Pour réaliser la deuxième tâche, il suffit d'estimer les paramètres de chaque distribution conditionnelle par maximum de vraisemblance, comme vous l'avez fait dans le TME 3. Ici, nous nous focaliserons donc plutôt sur l'apprentissage de structure. Celle-ci reflétant des indépendances conditionnelles entre variables aléatoires, vous devrez exploiter des tests d'indépendance du χ2 afin d'obtenir des structures graphiques les moins denses possibles (en termes de nombres d'arcs). Ainsi, alarm représente une distribution jointe de plus de 1016 événements élémentaires mais, quand cette distribution est décomposée grâce au graphe ci-dessous (les noeuds représentant les variables aléatoires), elle peut être décrite (sans perte d'informations) à l'aide de seulement 752 paramètres. Comme nous l'avons vu en cours, cette représentation permet également d'effectuer très rapidement des calculs probabilistes.\n",
    "\n",
    "![Image ](tme5_alarm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lecture des données\n",
    "\n",
    "Dans le code ci-dessous, la fonction `read_csv : string -> (string np.array, int np.2D-array, dico{string -> int} np.array)` vous permettra de lire les données des bases sur lesquelles vous allez travailler, et de les organiser sous une forme adéquate. Par exemple, une base de données est un fichier de la forme : \n",
    "\n",
    "```\n",
    " X_0,X_1,X_2,X_3\n",
    " haut,gauche,petit,bas\n",
    " bas,droite,grand,gauche\n",
    " bas,gauche,moyen,bas\n",
    "```\n",
    "\n",
    "\n",
    "Dans cette base, nous avons 4 variables aléatoires nommées X_0, X_1, X_2, et X_3, et 3 enregistrements qui représentent des instanciations (observées) de ces 4 variables. Ainsi, X_0 a pour valeurs haut, bas et bas, X_1 a pour valeurs gauche, droite, gauche, etc.\n",
    "\n",
    "La fonction `read_csv` prend en argument le nom d'un fichier CSV contenant une base de données et renvoie un triplet composé de :\n",
    "\n",
    "\n",
    "\n",
    "- 1 tableau numpy de strings contenant les noms des variables aléatoires. Par exemple, pour la base ci-dessus, ce tableau correspond à: \n",
    "```python\n",
    " n.array (['X_0', 'X_1', 'X_2', 'X_3'])\n",
    "```\n",
    "\n",
    "- un tableau numpy 2D contenant les données du fichier CSV encodées sous forme numérique (les valeurs des variables aléatoires sont transformées en nombres entiers): chaque ligne de ce tableau représente les intanciations d'une variable aléatoire et chaque colonne représente un enregistrement de la base de données, c'est-à-dire une instanciation/observation de toutes les variables aléatoires. Pour la base ci-dessus, nous obtiendrions le tableau ci-dessous (la signification des nombres est indiquée dans le dictionnaire précisé plus bas): \n",
    "```python\n",
    " np.array ( [ [0, 1, 1],   # instanciations de la variable X_0\n",
    "              [0, 1, 0],    # instanciations de la variable X_1\n",
    "              [0, 1, 2],    # instanciations de la variable X_2\n",
    "              [0, 1, 0]] )  # instanciations de la variable X_3\n",
    "```\n",
    "\n",
    "Ainsi, les valeurs observées de la première variable aléatoire X_0 correspondent à la première ligne du tableau (0, 1 et 1). La première colonne correspond à une observation de toutes les variables (X_0=0,X_1=0,X_2=0,X_3=0). C'est essentiellement sur ce tableau numpy que vous travaillerez dans ce TME. \n",
    "\n",
    "\n",
    "- un tableau numpy de dictionnaires faisant la correspondance, pour chaque variable aléatoire, entre l'encodage numérique du tableau 2D ci-dessus et les données du fichier CSV (le 1er dictionnaire correspond à la variable de la 1ère colonne du CSV, le 2ème dictionnaire à celle de la 2ème colonne, etc.). Ainsi, le dictionnaire est égal à : \n",
    "\n",
    "```python\n",
    "np.array( [ {'haut': 0, 'bas': 1},                  # encodage variable X_0\n",
    "             {'gauche': 0, 'droite': 1},            # encodage variable X_1\n",
    "             {'petit': 0, 'grand': 1, 'moyen': 2 }, # encodage variable X_2\n",
    "             {'bas': 0, 'gauche': 1} ] )            # encodage variable X_3\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "On peut ainsi reconstituer le CSV d'origine. Par exemple, la première colonne du tableau 2D ci-dessus, qui est égale à 0,0,0,0 correspond à haut,gauche,petit,bas: \"haut\" correspondant au 0 de la première variable aléatoire, \"gauche\" correspondant au 0 de la 2ème variable, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisez-le fichier [tme5_asia.csv](tme5_asia.csv) à l'aide de la fonction read_csv ci-dessous: la dernière instruction, `names, data, dico = read_csv ( \"tme5_asia.csv\" )`, vous permettra de récupérer, séparément, les trois champs du triplet renvoyé par la fonction read_csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# fonction pour transformer les données brutes en nombres de 0 à n-1\n",
    "def translate_data(data):\n",
    "    # création des structures de données à retourner\n",
    "    nb_variables = data.shape[0]\n",
    "    nb_observations = data.shape[1]-1 # - nom variable\n",
    "    res_data = np.zeros((nb_variables, nb_observations), int)\n",
    "    res_dico = np.empty(nb_variables, dtype=object)\n",
    "\n",
    "    # pour chaque variable, faire la traduction\n",
    "    for i in range (nb_variables):\n",
    "        res_dico[i] = {}\n",
    "        index = 0\n",
    "        for j in range (1, nb_observations + 1):\n",
    "            # si l'observation n'existe pas dans le dictionnaire, la rajouter\n",
    "            if data[i,j] not in res_dico[i]:\n",
    "                res_dico[i].update ({ data[i,j] : index })\n",
    "                index += 1\n",
    "            # rajouter la traduction dans le tableau de données à retourner\n",
    "            res_data[i,j-1] = res_dico[i][data[i,j]]\n",
    "    return (res_data, res_dico)\n",
    "\n",
    "\n",
    "# fonction pour lire les données de la base d'apprentissage\n",
    "def read_csv(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',', dtype=np.str).T\n",
    "    names = data[:,0].copy()\n",
    "    data, dico = translate_data(data)\n",
    "    return names, data, dico\n",
    "\n",
    "# names : tableau contenant les noms des variables aléatoires\n",
    "# data  : tableau 2D contenant les instanciations des variables aléatoires\n",
    "# dico  : tableau de dictionnaires contenant la correspondance (valeur de variable -> nombre)\n",
    "\n",
    "names, data, dico = read_csv(\"tme5_asia.csv\")\n",
    "print(names)\n",
    "print(data)\n",
    "print(dico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Statistique du $\\chi^2$ conditionnel\n",
    "\n",
    "\n",
    "Soit deux variables aléatoires $X$ et $Y$. Appelons $N_{xy}$, $N_x$ et $N_y$, respectivement, le nombre d'occurrences du couple $(X=x,Y=y)$ et des singletons $X=x$ et $Y=y$ dans la base de données. Alors, comme indiqué dans le cours 5, la statistique du $\\chi^2$ de $X$ et $Y$ est égale à : \n",
    "\n",
    "\n",
    "$$\\chi^2_{X,Y} = \\sum_x\\sum_y\\frac{\\left(N_{xy} - \\frac{N_x \\times N_y}{N}\\right)^2}{\\frac{N_x \\times N_y}{N}}$$\n",
    "\n",
    "où {$N$} représente le nombre de lignes de la base de données. Cette formule permet de tester l'indépendance entre les deux variables {$X$} et {$Y$}. On peut aisément généraliser celle-ci pour tester des indépendances conditionnellement à un ensemble de variables {$\\mathbf{Z}$}:\n",
    "\n",
    "$$\\chi^2_{X,Y|\\mathbf{Z}} = \\sum_x\\sum_y\\sum_{\\mathbf{z}}\\frac{\\left(N_{xy\\mathbf{z}} - \\frac{N_{x\\mathbf{z}} \\times N_{y\\mathbf{z}}}{N_{\\mathbf{z}}}\\right)^2}{\\frac{N_{x\\mathbf{z}} \\times N_{y\\mathbf{z}}}{N_{\\mathbf{z}}}}$$\n",
    "\n",
    "où $N_{xy\\mathbf{z}}$, $N_{x\\mathbf{z}}$, $N_{y\\mathbf{z}}$ et $N_{\\mathbf{z}}$ représentent, respectivement, le nombre d'occurrences du triplet $(X=x,Y=y,\\mathbf{Z} = \\mathbf{z})$, des couples $(X=x,\\mathbf{Z} = \\mathbf{z})$ et $(Y=y,\\mathbf{Z} = \\mathbf{z})$, et du singleton $\\mathbf{Z} = \\mathbf{z}$. Ainsi, si $\\mathbf{Z}$ est un ensemble de 3 variables aléatoires $(A,B,C)$, les valeurs $\\mathbf{z}$ seront des triplets $(a,b,c)$.\n",
    "\n",
    "Afin de vous aider à calculer ces $\\chi^2$, vous pourrez utiliser la fonction **create_contingency_table** `: int np.2D-array x dico{string -> int} np.array x int x int x int list -> (int, np.2D-array) np.array` ci-dessous. Celle-ci prend en argument le tableau 2D numpy `data` et le tableau de dictionnaires `dico` retournés à la fin de la question 1, ainsi que l'index `x` d'une variable aléatoire (0 = 1ère variable aléatoire (celle de la 1ère ligne de `data`), 1 = 2ème variable, _etc._), l'index `y` d'une autre variable et une liste `z` d'index d'autres variables aléatoires. Elle renvoie un tableau de couples ({$N_{\\mathbf{z}}, T_{X,Y,\\mathbf{z}})$}, pour tous les {$\\mathbf{z} \\in\\mathbf{Z}$}, où:\n",
    "\n",
    "*   $N_{\\mathbf{z}}$ représente le nombre d'occurences de {$Z=z$} dans la base de données. Par exemple, si la base de données est la suivante :\n",
    "\n",
    "```\n",
    " X_0,X_1,X_2,X_3\n",
    " haut,gauche,petit,bas\n",
    " bas,droite,grand,gauche\n",
    " bas,gauche,moyen,bas\n",
    "```\n",
    "\n",
    "nous avons vu plus haut que le tableau data est égal à : \n",
    "\n",
    "```python\n",
    "data = np.array ( [ [0, 1, 1],    # instanciations de la variable X_0\n",
    "                     [0, 1, 0],    # instanciations de la variable X_1\n",
    "                     [0, 1, 2],    # instanciations de la variable X_2\n",
    "                     [0, 1, 0]] )  # instanciations de la variable X_3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'application de **create_contingency_table ( data, dico, 0, 2, [3] ) **renverra le tableau: \n",
    "```python\n",
    "resultat = array([ (2, array([[ 1.,  0.,  0.],        # Z = 0 => N_{Z=0} = 2\n",
    "                               [ 0.,  0.,  1.]])),\n",
    "                    (1, array([[ 0.,  0.,  0.],        # Z = 1 => N_{Z=1} = 1\n",
    "                               [ 0.,  1.,  0.]])) ])\n",
    "```\n",
    "\n",
    "\n",
    "C'est a dire : \n",
    "Si $X_3=0$\n",
    "\n",
    "|  \t| $X_2$=0| $X_2$=1 \t| $X_2$=3 \t|\n",
    "|:-------:\t|:-------:\t|:-------:\t|:-------:\t|\n",
    "| $X_0$=0 \t|          1 \t| 0 \t| 0 \t|\n",
    "| $X_0$=1 \t|          0 \t| 0 \t| 1 \t|\n",
    "\n",
    "Si $X_3=1$\n",
    "\n",
    "|  \t| $X_2$=0| $X_2$=1 \t| $X_2$=3 \t|\n",
    "|:-------:\t|:-------:\t|:-------:\t|:-------:\t|\n",
    "| $X_0$=0 \t|          0 \t| 0 \t| 0 \t|\n",
    "| $X_0$=1 \t|          0 \t| 1 \t| 0 \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet le paramètre `[3]` indique que $\\mathbf{Z}$ est constitué uniquement de la quatrième variable de la base, autrement dit $X_3$. La dernière ligne du tableau `data` indique les instanciations de X_3 et l'on peut observer que la valeur 0 apparaît 2 fois et la valeur 1 apparaît une fois. On a donc $N_{Z=0} = 2$ et $N_{Z=1} = 1$. On peut observer que les valeurs de $N_{\\mathbf{Z}}$ sont bien les premiers éléments des couples de `resultat`. Lorsque $\\mathbf{Z} = \\emptyset$, `resultat` est un tableau avec un seul couple dont le premier élément correspond précisément à $N$, le nombre d'enregistrements de la base de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  $T_{X,Y,\\mathbf{z}}$ est un tableau 2D contenant le nombre d'occurrences $N_{xy\\mathbf{z}}$ des couples $(X=x,Y=y)$ lorsque $\\mathbf{Z}=\\mathbf{z}$. La première dimension de ce tableau (les lignes) correspondent aux différentes valeurs de $X$ et la deuxième (les colonnes) à celles de {$Y$}. Ainsi, le tableau en haut à droite de `resultat` est obtenu de la manière suivante: ce tableau correspond à des occurrences de $(X,Y)$ lorsque $\\mathbf{Z}=0$. on commence donc par extraire de `data` le sous-tableau correspondant à la première et à la troisième colonne (les colonnes où X_3=0) et on ne retient que les lignes correspondant à X_0 et X_2 (cf. les paramètres 0 et 2 passés en arguments de **create_contingency_table**). On obtient donc le sous-tableau:\n",
    "\n",
    "```python\n",
    "np.array ( [ [0, 1],    # instanciations de la variable X_0\n",
    "              [0, 2]] )  # instanciations de la variable X_2\n",
    "```\n",
    "\n",
    "Ce tableau nous indique que, lorsque $X_3=0$, les couples $(X_0=0,X_2=0)$ et $(X_0=1,X_2=2)$ apparaissent une seule fois et ce sont les seuls couples qui apparaissent dans la base de données. C'est précisément ce que représente le tableau en haut à droite de `resultat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etant donné une BD data et son dictionnaire, cette fonction crée le\n",
    "# tableau de contingence de (x,y) | z\n",
    "\n",
    "def create_contingency_table(data, dico, x, y, z):\n",
    "    # détermination de la taille de z\n",
    "    size_z = 1\n",
    "    offset_z = np.zeros(len(z))\n",
    "    j = 0\n",
    "    for i in z:\n",
    "        offset_z[j] = size_z      \n",
    "        size_z *= len(dico[i])\n",
    "        j += 1\n",
    "\n",
    "    # création du tableau de contingence\n",
    "    res = np.zeros(size_z, dtype = object)\n",
    "\n",
    "    # remplissage du tableau de contingence\n",
    "    if size_z != 1:\n",
    "        z_values = np.apply_along_axis(lambda val_z : val_z.dot(offset_z),\n",
    "                                         1, data[z,:].T)\n",
    "        i = 0\n",
    "        while i < size_z:\n",
    "            indices, = np.where(z_values == i)\n",
    "            a,b,c = np.histogram2d(data[x,indices], data[y,indices],\n",
    "                                    bins = [len(dico[x]), len(dico[y])])\n",
    "            res[i] = (indices.size, a)\n",
    "            i += 1\n",
    "    else:\n",
    "        a,b,c = np.histogram2d(data[x,:], data[y,:],\n",
    "                                bins = [len(dico[x]), len(dico[y])])\n",
    "        res[0] = (data.shape[1], a)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat=create_contingency_table(data, dico, 0, 2, [3]) \n",
    "print(resultat[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En utilisant la structure retournée par la fonction **create_contingency_table**, écrivez une fonction **sufficient_statistics**`: int np.2D-array x dico{string -> int} np.array x int x int x int list -> float` qui prend les mêmes arguments que la fonction **create_contingency_table** et qui renvoie la valeur de $\\chi^2_{X,Y|\\mathbf{Z}}$. Vous pourrez tirer profit du fait que $N_{x\\mathbf{z}} = \\sum_{y} N_{xy\\mathbf{z}}$ et $N_{y\\mathbf{z}} = \\sum_{x} N_{xy\\mathbf{z}}$, ce qui revient à faire des sommes sur chaque ligne ou chaque colonne des tableaux $T_{X,Y,\\mathbf{z}}$. \n",
    "\n",
    "**Attention :** il peut arriver que certains $N_{\\mathbf{z}}$ soient égaux à 0\\. Dans ce cas, vous ne tiendrez pas compte des $N_{xy\\mathbf{z}}$, $N_{x\\mathbf{z}}$ et $N_{y\\mathbf{z}}$ correspondants dans la formule de $\\chi^2_{X,Y|\\mathbf{Z}}$ (car vous feriez des divisions par 0, **ce qui est mal**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sufficient_statistics(data, dico, x, y, z):\n",
    "    # Création du tableau de contingence\n",
    "    table = create_contingency_table(data, dico, x, y, z)\n",
    "    nb_z = table.shape[0] # nombre de lignes au total : z=0, 1, 2... ?\n",
    "    nb_x, nb_y = table[0][1].shape # forme de Txyz\n",
    "    \n",
    "    # Sachant que Txyz contient les effectifs observés,\n",
    "    # il s'agit de sommer ses lignes puis ses colonnes pour chaque z \n",
    "    Nxz = np.zeros((nb_z,nb_x))\n",
    "    Nyz = np.zeros((nb_z,nb_y))\n",
    "    for z in range(nb_z):\n",
    "        if table[z][0]:  # on veille à éviter de prendre en compte des z nuls\n",
    "            Nxz[z] = table[z][1].sum(axis=1)\n",
    "            Nyz[z] = table[z][1].sum(axis=0)\n",
    "            \n",
    "    # Ensuite, on s'occupe du chi, qui est une double somme\n",
    "    chi = 0\n",
    "    for z in range(nb_z):\n",
    "        if table[z][0]:\n",
    "            for x in range(nb_x):\n",
    "                for y in range(nb_y):\n",
    "                    quant = (Nxz[z,x]*Nyz[z,y])/table[z][0]\n",
    "                    if quant: # cette grandeur ne doit pas être nulle, sans quoi on divise par 0\n",
    "                        chi += (table[z][1][x,y]-quant)**2/(quant)\n",
    "                        # note to self // table [z][1][x,y] : à rebours, c'est la case(x,y) du Txyz \n",
    "                        # situé à la ligne de la table de contingence qui correspond au z évalué\n",
    "    return chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vous pourrez vérifier la validité de vos calculs: en utilisant la base de données \"2015_tme5_asia.csv\", vous devriez obtenir les résultats suivants :\n",
    "\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|--------------------------------------------------\t|--------------------\t|\n",
    "| sufficient_statistics ( data, dico, 1,2,[3]) \t| 3.9466591186668296 \t|\n",
    "| sufficient_statistics ( data, dico, 0,1,[2,3]) \t| 16.355207462350094 \t|\n",
    "| sufficient_statistics ( data, dico, 1,3,[2]) \t| 81.807449348140295 \t|\n",
    "| sufficient_statistics ( data, dico, 5,2,[1,3,6]) \t| 1897.0 \t|\n",
    "| sufficient_statistics ( data, dico, 0,7,[4,5]) \t| 3.2223237760949699 \t|\n",
    "| sufficient_statistics ( data, dico, 2,3,[5]) \t| 130.0 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sufficient_statistics ( data, dico, 1,2,[3]     ))\n",
    "print(sufficient_statistics ( data, dico, 0,1,[2,3]   ))\n",
    "print(sufficient_statistics ( data, dico, 1,3,[2]     )) \n",
    "print(sufficient_statistics ( data, dico, 5,2,[1,3,6] ))\n",
    "print(sufficient_statistics ( data, dico, 0,7,[4,5]   ))\n",
    "print(sufficient_statistics ( data, dico, 2,3,[5]     ))\n",
    "\n",
    "# validé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistique du $\\chi^2$ et degré de liberté\n",
    "\n",
    "Modifiez votre fonction **sufficient_statistics** afin qu'elle ne renvoie plus seulement $\\chi^2_{X,Y|\\mathbf{Z}}$ mais plutôt un couple ($\\chi^2_{X,Y|\\mathbf{Z}}$,DoF), où DoF est le nombre de degrés de liberté de votre statistique. Celui-ci est égal à :\n",
    "\n",
    "$$(|X|-1) \\times (|Y|-1) \\times |\\{\\mathbf{z} : N_{\\mathbf{z}} \\neq 0\\}| $$\n",
    "\n",
    "où $|X|$ représente le nombre de valeurs possibles que peut prendre la variable $X$, autrement dit, c'est la taille de son dictionnaire. Le dernier terme de l'équation est simplement le nombre de $N_{\\mathbf{z}}$ différents de 0.\n",
    "\n",
    "Vous pourrez vérifier la validité de vos calculs: en utilisant la base de données \"2015_tme5_asia.csv\", vous devriez obtenir les résultats suivants:\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|:------------------------------------------------:\t|:-----------------------:\t|\n",
    "| sufficient_statistics ( data, dico, 1,2,[3]) \t| (3.9466591186668296, 2) \t|\n",
    "| sufficient_statistics ( data, dico, 0,1,[2,3]) \t| (16.355207462350094, 3) \t|\n",
    "| sufficient_statistics ( data, dico, 1,3,[2]) \t| (81.807449348140295, 2) \t|\n",
    "| sufficient_statistics ( data, dico, 5,2,[1,3,6]) \t| (1897.0, 8) \t|\n",
    "| sufficient_statistics ( data, dico, 0,7,[4,5]) \t| (3.2223237760949699, 4) \t|\n",
    "| sufficient_statistics ( data, dico, 2,3,[5]) \t| (130.0, 2) \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sufficient_statistics(data, dico, x, y, z):\n",
    "    # création du tableau de contingence\n",
    "    table = create_contingency_table(data, dico, x, y, z)\n",
    "    nb_z = table.shape[0]\n",
    "    nb_x, nb_y = table[0][1].shape\n",
    "    \n",
    "    desz = 0 # servira au comptage des différents z\n",
    "    chi = 0\n",
    "    \n",
    "    Nxz = np.zeros((nb_z,nb_x))\n",
    "    Nyz = np.zeros((nb_z,nb_y))\n",
    "    for z in range(nb_z):\n",
    "        if table[z][0]:\n",
    "            desz+=1 # on recense un nouveau z\n",
    "            Nxz[z] = table[z][1].sum(axis=1)\n",
    "            Nyz[z] = table[z][1].sum(axis=0)\n",
    "            \n",
    "            # on a factorisé les deux boucles : c'est possible et mieux\n",
    "            # on commence donc immédiatement les calculs du chi\n",
    "            for x in range(nb_x):\n",
    "                for y in range(nb_y):\n",
    "                    quant = (Nxz[z,x]*Nyz[z,y])/table[z][0]\n",
    "                    if quant:\n",
    "                        chi += (table[z][1][x,y]-quant)**2/(quant)\n",
    " \n",
    "    # calcul des degrés de liberté\n",
    "    dof = (len(dico[x])-1)*(len(dico[y])-1)*desz\n",
    "    return chi,dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sufficient_statistics ( data, dico, 1,2,[3]     ))\n",
    "print(sufficient_statistics ( data, dico, 0,1,[2,3]   ))\n",
    "print(sufficient_statistics ( data, dico, 1,3,[2]     )) \n",
    "print(sufficient_statistics ( data, dico, 5,2,[1,3,6] ))\n",
    "print(sufficient_statistics ( data, dico, 0,7,[4,5]   ))\n",
    "print(sufficient_statistics ( data, dico, 2,3,[5]     ))\n",
    "\n",
    "# validé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test d'indépendance\n",
    "\n",
    "En cours, nous avons vu que, pour un risque $\\alpha$ donné, si la statistique $\\chi^2_{X,Y|\\mathbf{Z}}$ est inférieure au seuil critique $c_{\\alpha}$ de la loi du $\\chi^2$ à DoF degrés de liberté, alors $X$ et $Y$ sont considérés comme indépendants conditionnellement à $\\mathbf{Z}$ ($X \\perp\\hspace{-1.7mm}\\perp Y | \\mathbf{Z}$). On peut reformuler cette propriété de la manière suivante :\n",
    "\n",
    "$$\\text{p-value}(\\chi^2_{X,Y|\\mathbf{Z}}) \\geq \\alpha \\Longleftrightarrow X \\perp\\hspace{-1.7mm}\\perp Y | \\mathbf{Z}$$\n",
    "\n",
    "La p-value d'un nombre x est l'intégrale de la fonction de densité de la loi du $\\chi^2$ de x à $+\\infty$ (autrement dit, c'est la surface de la partie grisée sur votre table du $\\chi^2$ à partir de l'abscisse x. On a donc p-value$(c_{\\alpha}) = \\alpha$. En statistiques, on considère qu'elle n'a du sens que si les valeurs du tableau de contingence sont toutes supérieures ou égales à 5 (autrement dit, un test d'indépendance du $\\chi^2$ n'est \"valide\" que si toutes les valeurs du tableau de contingence sont supérieures ou égales à 5). En informatique, on allège souvent cette règle en considérant que le test est valide dès lors que la valeur moyenne des cases est supérieure ou égale à 5\\. Cet allègement permet de tester la validité du test sans réaliser celui-ci : si le nombre de lignes du CSV est supérieure ou égale à $d_{min} = 5 \\times |X| \\times |Y| \\times |\\mathbf{Z}|$, le test est considéré comme valide.\n",
    "\n",
    "Ecrivez une fonction **indep_score** `: int np.2D-array x dico{string -> int} np.array x int x int x int list -> (float,int)` qui, étant donné les mêmes paramètres que ceux de la question précédente, vous renvoie un couple contenant la p-value correspondant à $\\chi^2_{X,Y|\\mathbf{Z}}$ ainsi que le nombre de degrés de liberté de cette statistique. Vous testerez au préalable si len ( data[0] ), le nombre de lignes/enregistrements de votre CSV, est supérieur ou non à $d_{min}$; si c'est inférieur, vous renverrez le couple (-1,1), qui représente une indépendance. Vous pourrez vous aider de la fonction scipy.stats.chi2.sf ( x, DoF ) qui renvoie la p-value (x) pour une loi à DoF degrés de liberté.\n",
    "\n",
    "``` python\n",
    "import scipy.stats as stats\n",
    "stats.chi2.sf ( x, DoF )\n",
    "```\n",
    "\n",
    "\n",
    "Vous pourrez vérifier la validité de vos calculs: en utilisant la base de données \"2015_tme5_asia.csv\", vous devriez obtenir les résultats suivants:\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|:----------------------------------------------:\t|:-----------------:\t|\n",
    "| indep_score ( data, dico, 1,3,[]) \t| 2.38520176938e-19 \t|\n",
    "| indep = indep_score ( data, dico, 1, 7, []) \t| 1.12562784979e-10 \t|\n",
    "| indep = indep_score ( data, dico, 0, 1,[2, 3]) \t| 0.000958828236575 \t|\n",
    "| indep = indep_score ( data, dico, 1, 2,[3, 4]) \t| 0.475266197894 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# fonction qui renvoie la p-value du test: x indépendant de y | z\n",
    "def indep_score(data, dico, x, y, z):\n",
    "    \n",
    "    # dictionnaire de z : produit cartésien des dictionnaires des variables de z\n",
    "    totalz = 1\n",
    "    for unz in z:\n",
    "        totalz*=len(dico[unz])\n",
    "    \n",
    "    if len(data[0])>=(5*len(dico[x])*len(dico[y])*totalz): # vérification de la validité\n",
    "        chi, dof = sufficient_statistics ( data, dico, x, y, z )\n",
    "        return (stats.chi2.sf(chi, dof),dof)  \n",
    "    return(-1,1) # on décide de traduire la non-validité par une indépendance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.385201769381993e-19, 1)\n",
      "(1.1256278497870963e-10, 1)\n",
      "(0.0009588282365754306, 3)\n",
      "(0.4752661978937994, 4)\n"
     ]
    }
   ],
   "source": [
    "print(indep_score ( data, dico, 1,3,[]     ))\n",
    "print(indep_score ( data, dico, 1, 7, []   ))\n",
    "print(indep_score ( data, dico, 0, 1,[2, 3]))\n",
    "print(indep_score ( data, dico, 1, 2,[3, 4]))\n",
    "\n",
    "# validé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Meilleur candidat pour être un parent (Partie optionnelle)\n",
    "\n",
    "Ecrivez une fonction **best_candidate** `: int np.2D-array x dico{string -> int} np.array x int x int list x float -> int list` qui, étant donné les tableaux `data` et `dico` calculés à la question 1, l'index d'une variable aléatoire $X$, la liste d'index d'un ensemble de variables aléatoires $\\mathbf{Z}$ et un risque $\\alpha$, détermine la variable $Y$ (en fait, l'index de sa colonne dans le CSV), parmi toutes celles à gauche de $X$ dans le fichier CSV, qui est la plus dépendante de $X$ conditionnellement à $\\mathbf{Z}$, autrement dit, celle qui a la plus petite p-value. Si cette p-value est supérieure à $\\alpha$, cela veut dire que $\\chi^2_{X,Y|\\mathbf{Z}}$ est inférieur à $c_{\\alpha}$ et donc que $Y$ est jugée indépendante de $X$ conditionnellement à $\\mathbf{Z}$. \n",
    "\n",
    "Votre fonction renverra une liste vide si $Y$ est indépendante de $X$ conditionnellement à $\\mathbf{Z}$, sinon elle renverra une liste contenant $Y$. Vous pourrez tester votre fonction avec $\\alpha$ = 0.05:\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|-----------------------------------------------\t|----------\t|\n",
    "| best_candidate ( data, dico, 1, [], 0.05 ) \t| [] \t|\n",
    "| best_candidate ( data, dico, 4, [], 0.05 ) \t| [1] \t|\n",
    "| best_candidate ( data, dico, 4, [1], 0.05 ) \t| [] \t|\n",
    "| best_candidate ( data, dico, 5, [], 0.05 ) \t| [3] \t|\n",
    "| best_candidate ( data, dico, 5, [6], 0.05 ) \t| [3] \t|\n",
    "| best_candidate ( data, dico, 5, [6,7], 0.05 ) \t| [2] \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui, étant donné un couple (x,z), renvoie une liste vide si tous\n",
    "# les y !=x,z sont indépendants de x conditionnellement à z, ou bien une\n",
    "# liste contenant le meilleur y (celui avec la p-value la plus petite) s'il\n",
    "# existe des y dont la p-value est inférieur au seuil\n",
    "\n",
    "# version np.array - donnait quelques soucis par la suite\n",
    "\"\"\"def best_candidate ( data, dico, x, z, risk_level ):\n",
    "    scores = np.zeros(x)\n",
    "    liste = []\n",
    "    for var in range(x):\n",
    "        scores[var] = indep_score(data, dico, x, var, z)[0] #indep x de y conditionnellement à z\n",
    "    if(scores[var]<=risk_level):\n",
    "        liste.append(np.where(scores == np.amin(scores))[0])\n",
    "    return liste\"\"\"\n",
    "\n",
    "# version liste - optimale\n",
    "def best_candidate(data, dico, x, z, risk_level):\n",
    "    if x==0:\n",
    "        return []\n",
    "    scores = [] # stocke les scores d'indépendance\n",
    "    liste = [] # sera la valeur de retour\n",
    "    for y in range(x): # valeurs à gauche de x\n",
    "        val = indep_score(data, dico, x, y, z)[0]\n",
    "        scores.append(val) # à \"quel point\" x est indépendant de y conditionnellement à z\n",
    "    if(min(scores)<=risk_level): \n",
    "        # si le minimum de ces scores est encore valable pour notre usage, récupérer le y associé\n",
    "        liste.append(scores.index(min(scores)))\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[]\n",
      "[3]\n",
      "[3]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(best_candidate ( data, dico, 1, [], 0.05    ))\n",
    "print(best_candidate ( data, dico, 4, [], 0.05    ))\n",
    "print(best_candidate ( data, dico, 4, [1], 0.05   ))\n",
    "print(best_candidate ( data, dico, 5, [], 0.05    ))\n",
    "print(best_candidate ( data, dico, 5, [6], 0.05   ))\n",
    "print(best_candidate ( data, dico, 5, [6,7], 0.05 ))\n",
    "\n",
    "# validé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Création des parents d'un noeud (Partie optionnelle)\n",
    "Ecrivez une fonction **create_parents** ( data, dico, x, alpha ) qui, étant donné une variable aléatoire x et un niveau de risque alpha, retourne la liste z de ses parents dans le réseau bayésien. L'algorithme est le suivant : partez de z = l'ensemble vide, puis tant que **best_candidate** ( x, z, alpha ) vous renvoie une liste non vide [y], rajoutez y à z. Lorsque vous sortirez de cette boucle, toutes les autres variables seront indépendantes de x conditionnellement à z.\n",
    "\n",
    "L'algorithme qui consiste à appliquer, pour chaque noeud/variable aléatoire, votre fonction **create_parents** correspond, en grande partie, à l'article suivant :\n",
    "\n",
    "Gregory F. Cooper and Edward Herskovits (1992) \"A Bayesian method for the induction of probabilistic networks from data\", _Machine Learning_, Vol. 9, n°4, pp. 309-347.  \n",
    "\n",
    "Vous pourrez tester la validité de votre fonction :\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|----------------------------------------\t|----------\t|\n",
    "| create_parents ( data, dico, 1, 0.05 ) \t| [] \t|\n",
    "| create_parents ( data, dico, 4, 0.05 ) \t| [1] \t|\n",
    "| create_parents ( data, dico, 5, 0.05 ) \t| [3, 2] \t|\n",
    "| create_parents ( data, dico, 6, 0.05 ) \t| [4, 5] \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[3, 2]\n",
      "[4, 5]\n"
     ]
    }
   ],
   "source": [
    "# pour un noeud donné, crée la liste de ses parents\n",
    "def create_parents(data, dico, x, risk_level):\n",
    "    z = []\n",
    "    y = best_candidate(data, dico, x, z, risk_level)\n",
    "    while y: # la boucle rompt au premier retour vide\n",
    "        z+=y\n",
    "        y = best_candidate(data, dico, x, z, risk_level)   \n",
    "    return z # z est resté vide s'il n'a pu accepter aucun candidat -> dans ce cas, il est le noeud racine\n",
    "\n",
    "print(create_parents ( data, dico, 1, 0.05 ))\n",
    "print(create_parents ( data, dico, 4, 0.05 ))\n",
    "print(create_parents ( data, dico, 5, 0.05 ))\n",
    "print(create_parents ( data, dico, 6, 0.05 ))\n",
    "\n",
    "# validé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apprentissage de la structure d'un réseau bayésien (Partie optionnelle)\n",
    "\n",
    "Ecrivez une fonction **learn_BN_structure** ( data, dico, alpha ) qui renvoie un tableau contenant, pour chaque noeud, la liste de ses parents. Ainsi, si votre fonction vous renvoie le tableau ci-dessous,\n",
    "```python\n",
    " array( [ [], [], [], [1, 0], [1], [3, 2], [4, 5], [5] ] )\n",
    "```\n",
    "\n",
    "les noeud correspondant aux 2 premières colonnes du CSV n'ont pas de parents, le noeud de la 3ème colonne a pour parent celui de la 1ère colonne, etc.\n",
    "\n",
    "Pour visualiser plus aisément votre structure, utilisez la fonction **display_BN** ci-dessous. Celle-ci prend en paramètres :\n",
    "\n",
    "1.  le tableau des noms des variables aléatoires déterminé à la question 1\n",
    "2.  la structure que vous avez calculée avec votre fonction **learn_BN_structure**\n",
    "3.  un nom que vous voulez donner à votre réseau\n",
    "4.  un style pour afficher les noeuds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage de la structure d'un réseau bayésien par K2\n",
    "\n",
    "def learn_BN_structure (data, dico, risk_level):\n",
    "    parents = []\n",
    "    # itération sur toutes les variables\n",
    "    for x in range(len(dico)):\n",
    "        parents.append(create_parents(data, dico, x, risk_level))\n",
    "    return parents\n",
    "\n",
    "bn_struct = learn_BN_structure(data, dico, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "style = { \"bgcolor\" : \"#6b85d1\", \"fgcolor\" : \"#FFFFFF\" }\n",
    "\n",
    "def display_BN ( node_names, bn_struct, bn_name, style ):\n",
    "    graph = pydotplus.Dot( bn_name, graph_type='digraph')\n",
    "\n",
    "    # création des noeuds du réseau\n",
    "    for name in node_names:\n",
    "        new_node = pydotplus.Node( name,\n",
    "                               style=\"filled\",\n",
    "                               fillcolor=style[\"bgcolor\"],\n",
    "                               fontcolor=style[\"fgcolor\"] )\n",
    "        graph.add_node( new_node )\n",
    "\n",
    "    # création des arcs\n",
    "    for node in range ( len ( node_names ) ):\n",
    "        parents = bn_struct[node]\n",
    "        for par in parents:\n",
    "            new_edge = pydotplus.Edge ( node_names[par], node_names[node] )\n",
    "            graph.add_edge ( new_edge )\n",
    "\n",
    "    # sauvegarde et affichage\n",
    "    outfile = bn_name + '.png'\n",
    "    graph.write_png( outfile )\n",
    "    img = mpimg.imread ( outfile )\n",
    "    plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7dcfecc70a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_BN\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbn_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"asia\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# remplacement de pydot par pydotplus dans le code pour obtenir l'affichage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-4d070eecd24a>\u001b[0m in \u001b[0;36mdisplay_BN\u001b[1;34m(node_names, bn_struct, bn_name, style)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# sauvegarde et affichage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0moutfile\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0moutfile\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "display_BN ( names, bn_struct, \"asia\", style )\n",
    "# remplacement de pydot par pydotplus dans le code pour obtenir l'affichage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fin de l'apprentissage et calcul probabiliste (Partie optionnelle)\n",
    "\n",
    "Comme précisé au début du TME, apprendre un réseau bayésien consiste à déterminer sa structure graphique et estimer ses paramètres. Vous avez réalisé la première partie. La deuxième, plus simple, peut se faire par maximum de vraisemblance pour chaque table de probabilité des noeuds conditionnellement à leurs parents, comme dans le TME 3\\. Utilisez la fonction **learn_parameters** ci-dessous pour effectuer cette tâche. Cette fonction prend en paramètres la structure graphique que vous avez apprise ainsi que le nom du fichier CSV que vous avez utilisé pour votre apprentissage. Elle renvoie un réseau bayésien à la [aGrUM](http://agrum.org). Pour pouvoir utiliser aGrUM, reportez-vous à la [question 7 du TME 2].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.ipython as gnb\n",
    "\n",
    "def learn_parameters ( bn_struct, ficname ):\n",
    "    # création du dag correspondant au bn_struct\n",
    "    graphe = gum.DAG ()\n",
    "    nodes = [ graphe.addNode () for i in range ( len(bn_struct) )]\n",
    "    for i in range ( len(bn_struct) ):\n",
    "        for parent in bn_struct[i]:\n",
    "            graphe.addArc ( nodes[parent], nodes[i] )\n",
    "\n",
    "    # appel au BNLearner pour apprendre les paramètres\n",
    "    learner = gum.BNLearner ( ficname )\n",
    "    learner.useScoreLog2Likelihood ()\n",
    "    learner.useAprioriSmoothing ()\n",
    "    return learner.learnParameters ( graphe )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vous pouvez maintenant réaliser des calculs probabilistes :\n",
    "\n",
    "- affichage de la taille du réseau bayésien\n",
    "\n",
    "```python\n",
    "# création du réseau bayésien à la aGrUM\n",
    "bn = learn_parameters ( bn_struct, ficname )\n",
    "\n",
    "# affichage de sa taille\n",
    "print(bn)\n",
    "```\n",
    "\n",
    "- affichage de la table de probabilité conditionnelle d'un noeud du réseau déterminé par son nom (1ère ligne du CSV):\n",
    "\n",
    "```python\n",
    "\n",
    "# récupération de la ''conditional probability table'' (CPT) et affichage de cette table\n",
    "gnb.showPotential( bn.cpt ( bn.idFromName ( 'bronchitis?' ) ) )\n",
    "```\n",
    "\n",
    "- calcul de la probabilité marginale d'un noeud : P('bronchitis?'):\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# calcul de la marginale\n",
    "proba = gum.getPosterior ( bn, {}, 'bronchitis?' )\n",
    "\n",
    "```\n",
    "\n",
    "- affichage graphique d'une distribution de probabilité marginale\n",
    "\n",
    "```python\n",
    "# affichage de la marginale\n",
    "gnb.showPotential( proba )\n",
    "\n",
    "```\n",
    "- calcul d'une distribution marginale a posteriori : P(bronchitis? | smoking? = true, turberculosis? = false )\n",
    "```python\n",
    "gnb.showPotential(gum.getPosterior ( bn,{'smoking?': 'true', 'tuberculosis?' : 'false' }, 'bronchitis?' ))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is my network like?\n",
      "BN{nodes: 8, arcs: 8, domainSize: 256, dim: 38}\n",
      "\n",
      "What makes it likely for me to have a bronchitis?\n",
      "          |---------------|\n",
      "----------|  bronchitis?  |\n",
      " smoking? | false   true  |\n",
      "----------|---------------|\n",
      "  false   | 0.6181 0.3819 |\n",
      "   true   | 0.2917 0.7083 |\n",
      "----------|---------------|\n",
      "\n",
      "According to the data, what are the chances for me to fall ill with bronchitis?\n",
      "|---------------|\n",
      "|  bronchitis?  |\n",
      "| false   true  |\n",
      "|---------------|\n",
      "| 0.4551 0.5449 |\n",
      "|---------------|\n",
      "\n",
      "Now, if I smoke and show no signs of tuberculosis, what will the chances be again?\n",
      "|---------------|\n",
      "|  bronchitis?  |\n",
      "| false   true  |\n",
      "|---------------|\n",
      "| 0.2917 0.7083 |\n",
      "|---------------|\n"
     ]
    }
   ],
   "source": [
    "bn = learn_parameters(bn_struct, \"tme5_asia.csv\")\n",
    "# erreur list object has no attribute \"shape\":\n",
    "# remplacement des bn_struct.shape[0] de la fonction fournie par des len(bn_struct)\n",
    "\n",
    "print(\"What is my network like?\")\n",
    "print(bn) # aspect du Network ?\n",
    "\n",
    "# probabilité conditionnelle (aux variables idoines) d'avoir une bronchite\n",
    "print(\"\\nWhat makes it likely for me to have a bronchitis?\")\n",
    "gnb.showPotential(bn.cpt(bn.idFromName('bronchitis?')))\n",
    "\n",
    "# probabilité marginale d'avoir une bronchite\n",
    "print(\"\\nAccording to the data, what are the chances for me to fall ill with bronchitis?\")\n",
    "proba = gum.getPosterior(bn, {}, 'bronchitis?')\n",
    "gnb.showPotential(proba)\n",
    "\n",
    "# distribution marginale a posteriori\n",
    "print(\"\\nNow, if I smoke and show no signs of tuberculosis, what will the chances be again?\")\n",
    "gnb.showPotential(gum.getPosterior(bn,{'smoking?':'true', 'tuberculosis?':'false'}, 'bronchitis?'))\n",
    "# Noter que la tuberculose, qu'elle soit là ou non, ne change rien du tout.\n",
    "# La distribution de la bronchite n'est impactée que par le caractère fumeur/non-fumeur.\n",
    "# C'est ce que montrait la probabilité conditionnelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. (Bonus) Autres bases de données\n",
    "\n",
    "Vous pouvez appliquer vos algorithmes sur des bases un peu plus conséquentes qu'asia:\n",
    "\n",
    "|  nom de la base  |            provenance           | nombre d'evenements elementaires |\n",
    "|:----------------:|:-------------------------------:|:--------------------------------:|\n",
    "|       asia       |          BN repository          |                $256     $          |\n",
    "|       alarm      |          BN repository          |              $10^{16}   $               |\n",
    "|       adult      | UCI machine learning repository |              $10^{12}   $          |\n",
    "|        car       | UCI machine learning repository |               $6912     $          |\n",
    "| agaricus-lepiota | UCI machine learning repository |              $10^{16}   $        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, data, dico = read_csv(\"mushroom_agaricus-lepiota.csv\")\n",
    "print(names)\n",
    "print(dico)\n",
    "\n",
    "\"\"\"\n",
    "    0.  class: edible=e, poisonous=p\n",
    "    1.  cap-shape: bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s\n",
    "    2.  cap-surface: fibrous=f, grooves=g, scaly=y, smooth=s\n",
    "    3.  cap-color: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "    4.  bruises: bruises=t, no=f\n",
    "    5.  odor: almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s\n",
    "    6.  gill-attachment: attached=a, descending=d, free=f, notched=n\n",
    "    7.  gill-spacing: close=c, crowded=w, distant=d\n",
    "    8.  gill-size: broad=b, narrow=n\n",
    "    9.  gill-color: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "    10. stalk-shape: enlarging=e, tapering=t\n",
    "    11. stalk-root: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=?\n",
    "    12. stalk-surface-above-ring: fibrous=f, scaly=y, silky=k, smooth=s\n",
    "    13. stalk-surface-below-ring: fibrous=f, scaly=y, silky=k, smooth=s\n",
    "    14. stalk-color-above-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "    15. stalk-color-below-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "    16. veil-type: partial=p, universal=u\n",
    "    17. veil-color: brown=n, orange=o, white=w, yellow=y\n",
    "    18. ring-number: none=n, one=o, two=t\n",
    "    19. ring-type: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z\n",
    "    20. spore-print-color: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y\n",
    "    21. population: abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y\n",
    "    22. habitat: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\n",
    "\"\"\"\n",
    "\n",
    "bn_struct = learn_BN_structure(data, dico, 0.05)\n",
    "\n",
    "bn = learn_parameters(bn_struct, \"mushroom_agaricus-lepiota.csv\")\n",
    "\n",
    "print(\"What is my network like?\")\n",
    "print(bn) # aspect du Network ?\n",
    "\n",
    "# probabilité conditionnelle (aux variables idoines) d'être un champignon venimeux\n",
    "print(\"\\nWhat makes it likely for me to die from eating this?\")\n",
    "gnb.showPotential(bn.cpt(bn.idFromName('class')))\n",
    "\n",
    "# probabilité marginale d'être venimeux\n",
    "print(\"\\nAccording to the data, what are the chances for a mushroom to be poisonous?\")\n",
    "proba = gum.getPosterior(bn, {}, 'class')\n",
    "gnb.showPotential(proba)\n",
    "\n",
    "# distribution marginale a posteriori\n",
    "print(\"\\nNow, if mine has bruises and smells of almonds, what will the chances be again?\")\n",
    "gnb.showPotential(gum.getPosterior(bn,{'bruises': 't', 'odor' : 'a'}, 'class'))\n",
    "\n",
    "# distribution marginale a posteriori\n",
    "print(\"\\nNow, if I found it standing alone in the woods, should I be confident and eat it?\")\n",
    "gnb.showPotential(gum.getPosterior(bn,{'population': 'y', 'habitat' : 'd'}, 'class'))\n",
    "\n",
    "# Fonctionne.\n",
    "# laisser tourner un petit moment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
